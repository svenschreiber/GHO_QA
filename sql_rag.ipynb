{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas chromadb ollama tqdm requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "from chromadb.utils.embedding_functions import DefaultEmbeddingFunction\n",
    "import ollama\n",
    "import re\n",
    "from pathlib import Path\n",
    "import requests\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display\n",
    "\n",
    "Path(\"data/indicators\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pulling manifest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pulling fd7b6731c33c: 100%|██████████| 9.05G/9.05G [00:00<00:00, 76.7TB/s]\n",
      "pulling 32695b892af8: 100%|██████████| 275/275 [00:00<00:00, 2.54MB/s]\n",
      "pulling fa8235e5b48f: 100%|██████████| 1.08k/1.08k [00:00<00:00, 11.7MB/s]\n",
      "pulling 45a1c652dddc: 100%|██████████| 82.0/82.0 [00:00<00:00, 1.15MB/s]\n",
      "pulling f5d6f49c6477: 100%|██████████| 486/486 [00:00<00:00, 6.29MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verifying sha256 digest\n",
      "writing manifest\n",
      "success\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def pull_ollama_model(model):\n",
    "    current_digest, bars = '', {}\n",
    "    for progress in ollama.pull(model, stream=True):\n",
    "        digest = progress.get('digest', '')\n",
    "        if digest != current_digest and current_digest in bars:\n",
    "            bars[current_digest].close()\n",
    "\n",
    "        if not digest:\n",
    "            print(progress.get('status'))\n",
    "            continue\n",
    "\n",
    "        if digest not in bars and (total := progress.get('total')):\n",
    "            bars[digest] = tqdm(total=total, desc=f'pulling {digest[7:19]}', unit='B', unit_scale=True)\n",
    "\n",
    "        if completed := progress.get('completed'):\n",
    "            bars[digest].update(completed - bars[digest].n)\n",
    "\n",
    "        current_digest = digest\n",
    "\n",
    "# Download Ollama model\n",
    "pull_ollama_model(\"phi4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically download the data for an indicator and filter/modify it's structure\n",
    "indicators = [\"NCD_DIABETES_PREVALENCE_AGESTD\", \"HIV_0000000026\", \"SA_0000001719\"]\n",
    "for indicator in indicators:\n",
    "    data = requests.get(f\"https://ghoapi.azureedge.net/api/{indicator}\").json()\n",
    "    df = pd.DataFrame(data['value'])\n",
    "\n",
    "    no_numeric = df[\"NumericValue\"].dropna(how=\"all\").empty\n",
    "\n",
    "    # Get dimension types\n",
    "    dim_type_map = {\"SpatialDim\": None, \"TimeDim\": None, \"Dim1\": None, \"Dim2\": None, \"Dim3\": None, }\n",
    "\n",
    "    # if there is a numeric value we use that as the main value, otherwise we use the general 'Value' column, which could also contain strings\n",
    "    if no_numeric: dim_type_map[\"Value\"] = \"value\"\n",
    "    else: dim_type_map[\"NumericValue\"] = \"value\"\n",
    "\n",
    "    dim_value_map = {}\n",
    "    for dim in dim_type_map.keys():\n",
    "        if dim_type_map[dim] is not None: continue\n",
    "        dim_type = df[dim+\"Type\"].mode(dropna=False)[0]\n",
    "        if dim_type is None or dim_type == \"\": continue \n",
    "        dim_values = requests.get(f\"https://ghoapi.azureedge.net/api/DIMENSION/{dim_type}/DimensionValues\").json()[\"value\"]\n",
    "        dim_value_map[dim_type.lower()] = {d[\"Code\"]: d[\"Title\"].lower() for d in dim_values}\n",
    "        dim_type_map[dim] = dim_type.lower()\n",
    "\n",
    "    # Remove unused dimensions\n",
    "    dim_map = {k: v for k,v in dim_type_map.items() if v is not None}\n",
    "\n",
    "    # Get indicator name\n",
    "    indicator_name = requests.get(f\"https://ghoapi.azureedge.net/api/Indicator?$filter=IndicatorCode eq '{indicator}'\").json()[\"value\"][0][\"IndicatorName\"]\n",
    "\n",
    "    # remove rows where the spatial and time dim differ from the one picked above\n",
    "    df = df.loc[df['SpatialDimType'].str.lower()==dim_type_map[\"SpatialDim\"]]\n",
    "    df = df.loc[df['TimeDimType'].str.lower()==dim_type_map[\"TimeDim\"]]\n",
    "\n",
    "    # Filter data to specific columns and rename to their actual names\n",
    "    filtered_df = df[dim_map.keys()]\n",
    "    filtered_df = filtered_df.rename(columns=dim_map)\n",
    "\n",
    "    # Map Value codes to their textual values\n",
    "    for dim, value_map in dim_value_map.items():\n",
    "        filtered_df[dim] = filtered_df[dim].map(value_map).fillna(filtered_df[dim])\n",
    "\n",
    "    # Save data to csv file\n",
    "    file_name = re.sub('[^0-9a-zA-Z]+', '_', indicator_name.lower())\n",
    "    filtered_df.to_csv(f\"data/indicators/{file_name}.csv\", index=False, sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to sqlite database (file will be created in the next step)\n",
    "db_path = \"data/gho.db\"\n",
    "conn = sqlite3.connect(db_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert csv file to sqlite database\n",
    "for indicator_file in glob(\"data/indicators/*.csv\"):\n",
    "    df = pd.read_csv(indicator_file, sep=\";\")\n",
    "    df.to_sql(indicator_file.split(\"/\")[-1][:-4], conn, if_exists=\"replace\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chroma DB vector store\n",
    "embedding_func = DefaultEmbeddingFunction()\n",
    "chroma_client = chromadb.EphemeralClient(settings=Settings(anonymized_telemetry=False))\n",
    "table_collection = chroma_client.get_or_create_collection(name=\"tables\", embedding_function=embedding_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CREATE TABLE \"advertising_restrictions_on_social_media\" (\\n\"country\" TEXT,\\n  \"year\" INTEGER,\\n  \"advertisingtype\" TEXT,\\n  \"value\" TEXT\\n)', 'CREATE TABLE \"number_of_new_hiv_infections\" (\\n\"country\" TEXT,\\n  \"year\" INTEGER,\\n  \"value\" REAL\\n)', 'CREATE TABLE \"prevalence_of_diabetes_age_standardized\" (\\n\"country\" TEXT,\\n  \"year\" INTEGER,\\n  \"sex\" TEXT,\\n  \"agegroup\" TEXT,\\n  \"value\" REAL\\n)']\n"
     ]
    }
   ],
   "source": [
    "# Store table ddls in chroma db\n",
    "ddls = pd.read_sql_query(\"SELECT type, sql FROM sqlite_master WHERE sql is not null\", conn)\n",
    "ddls = ddls['sql'].to_list()\n",
    "table_collection.add(documents=ddls, ids=[f\"id{i}\" for i in range(len(ddls))])\n",
    "\n",
    "print(ddls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 10 is greater than number of elements in index 3, updating n_results = 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a SQLite expert. Please help to generate a SQL query to answer the question. Your response should ONLY be based on the given context and follow the response guidelines and format instructions. \n",
      "\n",
      "===Tables \n",
      "CREATE TABLE \"number_of_new_hiv_infections\" (\n",
      "\"country\" TEXT,\n",
      "  \"year\" INTEGER,\n",
      "  \"value\" REAL\n",
      ")\n",
      "\n",
      "CREATE TABLE \"advertising_restrictions_on_social_media\" (\n",
      "\"country\" TEXT,\n",
      "  \"year\" INTEGER,\n",
      "  \"advertisingtype\" TEXT,\n",
      "  \"value\" TEXT\n",
      ")\n",
      "\n",
      "CREATE TABLE \"prevalence_of_diabetes_age_standardized\" (\n",
      "\"country\" TEXT,\n",
      "  \"year\" INTEGER,\n",
      "  \"sex\" TEXT,\n",
      "  \"agegroup\" TEXT,\n",
      "  \"value\" REAL\n",
      ")\n",
      "\n",
      "===Response Guidelines \n",
      "1. Generate valid SQL if the context is sufficient. Ensure it is SQLite-compliant and error-free. \n",
      "2. If the provided context is almost sufficient but requires knowledge of a specific string in a particular column, generate only an intermediate query to retrieve relevant information. \n",
      "3. Mark intermediate queries with '<intermediate>' and output only the query. No explanations or comments. \n",
      "4. Use the most relevant tables only. \n",
      "5. Use LIKE for filtering TEXT columns unless otherwise specified. \n",
      "6. Repeat previous answers exactly for repeated questions. \n",
      "7. Avoid unnecessary complexity. Make the queries as short as possible. Do not focus on too many things at once. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create system prompt for question\n",
    "user_prompt = \"What is the average number of HIV infections in countries that have banned beer advertisements?\"\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are a SQLite expert. \"\n",
    "    \"Please help to generate a SQL query to answer the question. Your response should ONLY be based on the given context and follow the response guidelines and format instructions. \\n\\n\"\n",
    ")\n",
    "\n",
    "system_prompt += \"===Tables \\n\"\n",
    "ddls = table_collection.query(query_texts=user_prompt, n_results=10)[\"documents\"][0]\n",
    "for ddl in ddls:\n",
    "    system_prompt += ddl + \"\\n\\n\"\n",
    "\n",
    "system_prompt += (\n",
    "    \"===Response Guidelines \\n\"\n",
    "    \"1. Generate valid SQL if the context is sufficient. Ensure it is SQLite-compliant and error-free. \\n\"\n",
    "    \"2. If the provided context is almost sufficient but requires knowledge of a specific string in a particular column, generate only an intermediate query to retrieve relevant information. \\n\"\n",
    "    \"3. Mark intermediate queries with '<intermediate>' and output only the query. No explanations or comments. \\n\"\n",
    "    \"4. Use the most relevant tables only. \\n\"\n",
    "    \"5. Use LIKE for filtering TEXT columns unless otherwise specified. \\n\"\n",
    "    \"6. Repeat previous answers exactly for repeated questions. \\n\"\n",
    "    \"7. Avoid unnecessary complexity. Make the queries as short as possible. Do not focus on too many things at once. \\n\"\n",
    ")\n",
    "\n",
    "# Implement intermediate_sql prompting\n",
    "print(system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```sql\n",
      "<intermediate>\n",
      "SELECT DISTINCT nr.country\n",
      "FROM advertising_restrictions_on_social_media AS nr\n",
      "WHERE nr.advertisingtype LIKE 'beer' AND nr.value = 'banned';\n",
      "</intermediate>\n",
      "\n",
      "SELECT AVG(hn.value) AS average_hiv_infections\n",
      "FROM number_of_new_hiv_infections AS hn\n",
      "JOIN (\n",
      "    SELECT DISTINCT nr.country\n",
      "    FROM advertising_restrictions_on_social_media AS nr\n",
      "    WHERE nr.advertisingtype LIKE 'beer' AND nr.value = 'banned'\n",
      ") AS banned_countries ON hn.country = banned_countries.country;\n",
      "```\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [country]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```sql\n",
      "select avg(hn.value) as average_hiv_infections\n",
      "from number_of_new_hiv_infections as hn\n",
      "join (\n",
      "    select distinct nr.country\n",
      "    from advertising_restrictions_on_social_media as nr\n",
      "    where nr.advertisingtype like 'beer' and nr.value = 'banned'\n",
      ") as banned_beverage_countries on hn.country = banned_beverage_countries.country;\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "def extract_sql(response, intermediate=False):\n",
    "    rules = [r\"\\bWITH\\b .*?;\", r\"SELECT.*?;\", r\"```sql\\n(.*)```\", r\"```(.*)```\"]\n",
    "    for rule in rules:\n",
    "        if sqls := re.findall(rule, response, re.DOTALL): \n",
    "            #print(\"---\\n\".join(sqls))\n",
    "            return sqls[0] if intermediate else sqls[-1]\n",
    "    return response\n",
    "\n",
    "# Create message log\n",
    "messages = [\n",
    "    {'role': 'system', 'content': system_prompt},\n",
    "    {'role': 'user', 'content': user_prompt},\n",
    "]\n",
    "\n",
    "# Prompt an LLM.\n",
    "response = ollama.chat(model=\"phi4\", messages=messages, options=dict(num_ctx=16384))[\"message\"][\"content\"]\n",
    "print(response)\n",
    "\n",
    "if \"<intermediate>\" in response:\n",
    "    intermediate_sql = extract_sql(response, True).lower()\n",
    "    df = pd.read_sql_query(intermediate_sql, conn)\n",
    "    display(df)\n",
    "    intermediate_prompt = (\n",
    "        \"===Previous Intermediate Query Results \\n\" \n",
    "        f\"Intermediate SQL Query: \\n```sql\\n{intermediate_sql}\\n```\\n\"\n",
    "        f\"Results: \\n{df.to_markdown()}\\n\" \n",
    "        \"Generate a final SQL query based on these intermediate results. No explanations or comments. \\n\"\n",
    "    )\n",
    "    messages = [\n",
    "        {'role': 'system', 'content': system_prompt},\n",
    "        {'role': 'user', 'content': user_prompt},\n",
    "        {'role': 'system', 'content': intermediate_prompt},\n",
    "    ]\n",
    "    response = ollama.chat(model=\"phi4\", messages=messages, options=dict(num_ctx=16384))[\"message\"][\"content\"]\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>average_hiv_infections</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  average_hiv_infections\n",
       "0                   None"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sql = extract_sql(response).lower()\n",
    "df = pd.read_sql_query(sql, conn)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The HIV infection rate decreased steadily from 2000 to 2023, dropping from approximately 2.33 million infections in 2000 to around 944,230 infections in 2022, before a slight increase to 963,630 infections in 2023.\n"
     ]
    }
   ],
   "source": [
    "# We now prompt again to summarize the contents of the DataFrame\n",
    "messages = [\n",
    "    {'role': 'system', 'content': f\"You are a helpful data assistant. The user asked the question: '{user_prompt}'\\n\\nThe following is a pandas DataFrame with the results of the query: \\n{df.to_markdown()}\\n\\n\"},\n",
    "    {'role': 'user', 'content': \"Briefly summarize the data based on the question that was asked. Do not respond with any additional explanation beyond the summary. If you were provided with factual data, use it.\"},\n",
    "]\n",
    "\n",
    "response = ollama.chat(model=\"phi4\", messages=messages, options=dict(num_ctx=16384))\n",
    "print(response[\"message\"][\"content\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
