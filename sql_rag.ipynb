{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "from chromadb.utils.embedding_functions import DefaultEmbeddingFunction\n",
    "import ollama\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to sqlite database\n",
    "db_path = \"data/gho.db\"\n",
    "#os.remove(db_path) if os.path.exists(db_path) else None # clear db if it exists\n",
    "conn = sqlite3.connect(db_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41580"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert csv file to sqlite database\n",
    "df = pd.read_csv(\"data/filtered.csv\", sep=\";\")\n",
    "df.to_sql(\"diabetes_prevalence\", conn, if_exists=\"replace\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chroma DB vector store\n",
    "embedding_func = DefaultEmbeddingFunction()\n",
    "chroma_client = chromadb.EphemeralClient(settings=Settings(anonymized_telemetry=False))\n",
    "table_collection = chroma_client.get_or_create_collection(name=\"tables\", embedding_function=embedding_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Add of existing embedding ID: id0\n",
      "Insert of existing embedding ID: id0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CREATE TABLE \"diabetes_prevalence\" (\\n\"country\" TEXT,\\n  \"year\" INTEGER,\\n  \"sex\" TEXT,\\n  \"agegroup\" TEXT,\\n  \"value\" REAL\\n)']\n"
     ]
    }
   ],
   "source": [
    "# Store table ddls in chroma db\n",
    "ddls = pd.read_sql_query(\"SELECT type, sql FROM sqlite_master WHERE sql is not null\", conn)\n",
    "ddls = ddls['sql'].to_list()\n",
    "table_collection.add(documents=ddls, ids=[f\"id{i}\" for i in range(len(ddls))])\n",
    "\n",
    "print(ddls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 10 is greater than number of elements in index 1, updating n_results = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Tables \n",
      "CREATE TABLE \"diabetes_prevalence\" (\n",
      "\"country\" TEXT,\n",
      "  \"year\" INTEGER,\n",
      "  \"sex\" TEXT,\n",
      "  \"agegroup\" TEXT,\n",
      "  \"value\" REAL\n",
      ")\n",
      "\n",
      "===Response Guidelines \n",
      "1. If the provided context is sufficient, please generate a valid SQL query without any explanations for the question. \n",
      "2. If the provided context is almost sufficient but requires knowledge of a specific string in a particular column, please generate an intermediate SQL query to find the distinct strings in that column. Prepend the query with a comment saying intermediate_sql \n",
      "3. If the provided context is insufficient, please explain why it can't be generated. \n",
      "4. Please use the most relevant table(s). \n",
      "5. If the answer depends on table columns which the user did not anticipate, include them reasonably. \n",
      "6. If the question has been asked and answered before, please repeat the answer exactly as it was given before. \n",
      "7. Ensure that the output SQL is SQLite-compliant and executable, and free of syntax errors. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create system prompt for question\n",
    "user_prompt = \"How did the diabetes prevalence change in papua new guinea?\"\n",
    "\n",
    "system_prompt = \"===Tables \\n\"\n",
    "ddls = table_collection.query(query_texts=user_prompt, n_results=10)[\"documents\"][0]\n",
    "for ddl in ddls:\n",
    "    system_prompt += ddl + \"\\n\\n\"\n",
    "\n",
    "system_prompt += (\n",
    "    \"===Response Guidelines \\n\"\n",
    "    \"1. If the provided context is sufficient, please generate a valid SQL query without any explanations for the question. \\n\"\n",
    "    \"2. If the provided context is almost sufficient but requires knowledge of a specific string in a particular column, please generate an intermediate SQL query to find the distinct strings in that column. Prepend the query with a comment saying intermediate_sql \\n\"\n",
    "    \"3. If the provided context is insufficient, please explain why it can't be generated. \\n\"\n",
    "    \"4. Please use the most relevant table(s). \\n\"\n",
    "    \"5. If the answer depends on table columns which the user did not anticipate, include them reasonably. \\n\"\n",
    "    \"6. If the question has been asked and answered before, please repeat the answer exactly as it was given before. \\n\"\n",
    "    f\"7. Ensure that the output SQL is SQLite-compliant and executable, and free of syntax errors. \\n\"\n",
    ")\n",
    "\n",
    "# Implement intermediate_sql prompting\n",
    "print(system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```sql\n",
      "SELECT year, value\n",
      "FROM diabetes_prevalence\n",
      "WHERE country = 'Papua New Guinea'\n",
      "ORDER BY year;\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# Create message log\n",
    "messages = [\n",
    "    {'role': 'system', 'content': system_prompt},\n",
    "    {'role': 'user', 'content': user_prompt},\n",
    "]\n",
    "\n",
    "# Prompt an LLM. We use Phi-4, because it proved to be better at generating SQL queries compared to Llama3.1:8b.\n",
    "response = ollama.chat(model=\"phi4\", messages=messages)\n",
    "sql = response[\"message\"][\"content\"]\n",
    "print(sql)\n",
    "\n",
    "# TODO: run LLM again if response contains 'intermediate_sql'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1990</td>\n",
       "      <td>17.75252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1990</td>\n",
       "      <td>14.29857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1990</td>\n",
       "      <td>17.06165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1990</td>\n",
       "      <td>15.77512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1990</td>\n",
       "      <td>20.99082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>2022</td>\n",
       "      <td>26.43813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>2022</td>\n",
       "      <td>25.07183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>2022</td>\n",
       "      <td>20.79233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>2022</td>\n",
       "      <td>21.62208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>2022</td>\n",
       "      <td>25.77786</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     year     value\n",
       "0    1990  17.75252\n",
       "1    1990  14.29857\n",
       "2    1990  17.06165\n",
       "3    1990  15.77512\n",
       "4    1990  20.99082\n",
       "..    ...       ...\n",
       "193  2022  26.43813\n",
       "194  2022  25.07183\n",
       "195  2022  20.79233\n",
       "196  2022  21.62208\n",
       "197  2022  25.77786\n",
       "\n",
       "[198 rows x 2 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_sql(response):\n",
    "    rules = [r\"\\bWITH\\b .*?;\", r\"SELECT.*?;\", r\"```sql\\n(.*)```\", r\"```(.*)```\"]\n",
    "    for rule in rules:\n",
    "        if sqls := re.findall(rule, response, re.DOTALL): return sqls[-1]\n",
    "    return response\n",
    "\n",
    "sql = extract_sql(sql).lower()\n",
    "df = pd.read_sql_query(sql, conn)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5595\n",
      "The prevalence of diabetes in Papua New Guinea fluctuated from 1990 to 2022, but generally increased over time. In 1990, the average prevalence rate was around 16-20%. By 2005, it had risen to approximately 18-22%, and continued to increase, reaching a peak of around 26% in 2014-2016. The prevalence rate remained stable or slightly decreased after 2017, with values ranging from 24-26% in 2022.\n"
     ]
    }
   ],
   "source": [
    "# We now prompt again to summarize the contents of the DataFrame\n",
    "messages = [\n",
    "    {'role': 'system', 'content': f\"You are a helpful data assistant. The user asked the question: '{user_prompt}'\\n\\nThe following is a pandas DataFrame with the results of the query: \\n{df.to_markdown()}\\n\\n\"},\n",
    "    {'role': 'user', 'content': \"Briefly summarize the data based on the question that was asked. Do not respond with any additional explanation beyond the summary.\"},\n",
    "]\n",
    "\n",
    "# Even though Llama3.1:8b performs worse than Phi-4 we use it here, because of its much bigger context length.\n",
    "# Sometimes the dataframes provided in the prompt are so long that they don't fit in the context window of Phi-4.\n",
    "response = ollama.chat(model=\"llama3.1:8b\", messages=messages, options=dict(num_ctx=32768))\n",
    "print(response[\"message\"][\"content\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
